{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e01e82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data aquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99275e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data aquisition\n",
    "\n",
    "Un modèle de data science se décompose comme suit:\n",
    "\n",
    "1. Collecte des données\n",
    "2. Nettoyage des données\n",
    "3. Modélisation des données\n",
    "4. Prédiction des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9071e",
   "metadata": {},
   "source": [
    "**Ce jupyter porte uniquement sur le point 1, la collecte de données**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea0b00",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Techniques de collecte de données\n",
    "\n",
    "Il existe plusieurs techniques de collecte de données:\n",
    "\n",
    "- Scraper\n",
    "- Web scraping\n",
    "- Web scraping avec Selenium\n",
    "- REST API\n",
    "- DataSets (Kaggle, UCI, yfinance, seaborn, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d916036",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scrapper\n",
    "\n",
    "Le scrapper est une technique de collecte de données qui permet de collecter les données d'une page web ou autre support.\n",
    "\n",
    "### Web scraping\n",
    "\n",
    "Le web scraping est une technique de collecte de données qui permet de collecter les données d'une page web statique.\n",
    "\n",
    "### Web scraping avec Selenium\n",
    "\n",
    "Le web scraping avec Selenium est une technique de collecte de données qui permet de collecter les données d'une page web dynamique. Contrairement au web scraping, le web scraping avec Selenium permet de collecter les données d'une page web dynamique. Il agit comme un humain et permet de collecter des données qui sont visible seulement après certaines actions (clic, scroll, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c3571",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### REST API\n",
    "\n",
    "Les API REST sont des API en ligne qui permettent de retourner des données à la suite d'une requête HTTP. Les données sont retournées dans un format standardisé (JSON, XML, etc.).\n",
    "\n",
    "### DataSets\n",
    "\n",
    "Les DataSets sont des jeux de données qui sont disponibles en ligne. Ils sont souvent utilisés pour l'entrainement de modèles de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665bfdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## L'objet requests\n",
    "\n",
    "L'objet requests permet de faire des requêtes HTTP. Il permet de récupérer le contenu d'une page web.\n",
    "Nous utiliseront cet objet pour faire du web scraping. Car il faut récupérer le contenu d'une page web à l'aide d'une requête avant de pouvoir faire du web scraping.\n",
    "\n",
    "Pour installer l'objet requests, il faut utiliser la commande suivante:\n",
    "\n",
    "```bash\n",
    "conda install -c anaconda requests\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5687286",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "wiki = requests.get(\"https://en.wikipedia.org/wiki/Python_(programming_language)\")\n",
    "\n",
    "print(wiki.status_code)\n",
    "print(wiki.text)\n",
    "print(wiki.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7c972",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Web scraping\n",
    "\n",
    "Pour faire du web scraping **simple**, on peut utiliser la librairie BeautifulSoup.\n",
    "\n",
    "pour installer executer la commande suivante dans l'environement conda:\n",
    "\n",
    "```bash\n",
    "conda install -c anaconda beautifulsoup4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6d0f7",
   "metadata": {},
   "source": [
    "#### BeautifulSoup\n",
    "\n",
    "BeautifulSoup est une librairie qui permet de faire du web scraping. Elle permet de récupérer des données d'une page web statique.\n",
    "Elle permet de `parser` le code HTML d'une page web et de récupérer les données qui nous intéresse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b67bf9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c1b7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://quotes.toscrape.com/page/2/\"\n",
    "\n",
    "# Get the HTML page\n",
    "response = requests.get(url)\n",
    "#print(response.text)\n",
    "\n",
    "# Parse the HTML page\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81c7421",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get the quotes\n",
    "quotes = soup.find_all(\"div\", class_=\"quote\")\n",
    "#quotes = soup.select(\".quote\")\n",
    "\n",
    "# Get the author and the quote\n",
    "for quote in quotes:\n",
    "    author = quote.find(\"small\", class_=\"author\").text\n",
    "    quote_text = quote.find(\"span\", class_=\"text\").text\n",
    "    print(f\"{author} said: {quote_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e608ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tags_dict = {}\n",
    "# count all tags\n",
    "for quote in quotes:\n",
    "    tags = quote.find_all(\"a\", class_=\"tag\")\n",
    "    for tag in tags:\n",
    "        tag_text = tag.text\n",
    "        if tag_text in tags:\n",
    "            tags_dict[tag_text] += 1\n",
    "        else:\n",
    "            tags_dict[tag_text] = 1\n",
    "\n",
    "print(tags_dict)\n",
    "tags_dict[\"heartbreak\"] += 1\n",
    "print(max(tags_dict, key=tags_dict.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4e6ef8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### BeautifulSoup Methods\n",
    "\n",
    "voici une liste des methodes de BeautifulSoup:\n",
    "\n",
    "| Methode | Description |\n",
    "| --- | --- |\n",
    "| `find()` | Retourne le premier élément qui correspond au filtre |\n",
    "| `find_all()` | Retourne tous les éléments qui correspondent au filtre |\n",
    "| `find_parent()` | Retourne le parent de l'élément |\n",
    "| `find_next_sibling()` | Retourne le prochain élément du même niveau |\n",
    "| `find_previous_sibling()` | Retourne le précédent élément du même niveau |\n",
    "| `find_next()` | Retourne le prochain élément |\n",
    "| `find_previous()` | Retourne le précédent élément |\n",
    "| `find_all_next()` | Retourne tous les éléments suivants |\n",
    "| `find_all_previous()` | Retourne tous les éléments précédents |\n",
    "| `select()` | Retourne tous les éléments qui correspondent au filtre CSS |\n",
    "| `select_one()` | Retourne le premier élément qui correspond au filtre CSS |\n",
    "| `prettify()` | Retourne le code HTML formaté |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e9cf0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### BeautifulSoup Attributes\n",
    "\n",
    "voici une liste des attributs de BeautifulSoup:\n",
    "\n",
    "| Attribut | Description |\n",
    "| --- | --- |\n",
    "| `name` | Retourne le nom de la balise |\n",
    "| `attrs` | Retourne les attributs de la balise |\n",
    "| `string` | Retourne le contenu de la balise |\n",
    "| `text` | Retourne le contenu de la balise |\n",
    "| `contents` | Retourne le contenu de la balise |\n",
    "| `children` | Retourne les enfants de la balise |\n",
    "| `parent` | Retourne le parent de la balise |\n",
    "| `next_sibling` | Retourne le prochain élément du même niveau |\n",
    "| `previous_sibling` | Retourne le précédent élément du même niveau |\n",
    "| `next` | Retourne le prochain élément |\n",
    "| `previous` | Retourne le précédent élément |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb844b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Web scraping with Selenium\n",
    "\n",
    "Pour faire du web scraping **avancé**, on peut utiliser la librairie Selenium. Elle permet de faire du web scraping sur des pages web dynamiques.\n",
    "Selenium permet de simuler un navigateur web et d'interagir avec une page web comme un humain. On pourra donc récupérer des données qui sont visible seulement après certaines actions (clic, scroll, etc.).\n",
    "\n",
    "**Note: `Selenium` est souvent utilisé pour faire du web unit testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6741cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Selenium Installation\n",
    "\n",
    "Pour utiliser Selenium, il faut d'abord installer la librairie:\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge selenium\n",
    "```\n",
    "\n",
    "Ensuite il faut installer le driver du navigateur web que l'on souhaite utiliser:\n",
    "\n",
    "- Chrome : https://googlechromelabs.github.io/chrome-for-testing/#stable\n",
    "- Edge : https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/\n",
    "- Firefox : https://github.com/mozilla/geckodriver/releases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493026fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Selenium - XPATH\n",
    "\n",
    "XPATH est un langage de requête qui permet de sélectionner des éléments dans un document XML ou HTML. Il permet de sélectionner des éléments dans une page web. voir [ici](https://www.w3schools.com/xml/xpath_syntax.asp). Il est possible d'utiliser XPATH dans Selenium.\n",
    "\n",
    "##### XPATH Syntax\n",
    "\n",
    "| Expression | Description |\n",
    "| --- | --- |\n",
    "| `nodename` | Selects all nodes with the name \"nodename\" |\n",
    "| `/` | Selects from the root node |\n",
    "| `//` | Selects nodes in the document from the current node that match the selection no matter where they are |\n",
    "| `.` | Selects the current node |\n",
    "| `..` | Selects the parent of the current node |\n",
    "| `@` | Selects attributes |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9189e2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### XPATH Examples\n",
    "\n",
    "| Expression | Description |\n",
    "| --- | --- |\n",
    "| `//span[@class='a-size-medium a-color-base a-text-normal']` | Selects all span elements with the class \"a-size-medium a-color-base a-text-normal\" |\n",
    "| `//span[@class='a-size-medium a-color-base a-text-normal']/text()` | Selects all span elements with the class \"a-size-medium a-color-base a-text-normal\" and returns the text |\n",
    "| `//div[@id='nav-xshop']/a` | Selects all a elements in the div with the id \"nav-xshop\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340818ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Selenium - CSS\n",
    "\n",
    "CSS est un langage qui permet de définir le style d'un document HTML. Il permet de sélectionner des éléments dans une page web. voir [ici](https://www.w3schools.com/cssref/css_selectors.asp). Il est possible d'utiliser CSS dans Selenium.\n",
    "\n",
    "##### CSS Syntax\n",
    "\n",
    "| Expression | Description |\n",
    "| --- | --- |\n",
    "| `*` | Selects all elements |\n",
    "| `#id` | Selects the element with the id \"id\" |\n",
    "| `.quote` | Selects all elements with the class \"class\" |\n",
    "| `element` | Selects all elements with the tag \"element\" |\n",
    "| `element.class` | Selects all elements with the tag \"element\" and the class \"class\" |\n",
    "| `element,element` | Selects all elements with the tag \"element\" or \"element\" |\n",
    "| `element element` | Selects all elements with the tag \"element\" inside the element with the tag \"element\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab224d7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### CSS Examples\n",
    "\n",
    "| Expression | Description |\n",
    "| --- | --- |\n",
    "| `span.a-size-medium.a-color-base.a-text-normal` | Selects all span elements with the class \"a-size-medium a-color-base a-text-normal\" |\n",
    "| `span.a-size-medium.a-color-base.a-text-normal` | Selects all span elements with the class \"a-size-medium a-color-base a-text-normal\" |\n",
    "| `div#nav-xshop a` | Selects all a elements in the div with the id \"nav-xshop\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4088da2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selenium example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024018c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Selenium Methods\n",
    "\n",
    "voici une liste des methodes de Selenium:\n",
    "\n",
    "| Methode | Description |\n",
    "| --- | --- |\n",
    "| `get()` | Ouvre une page web |\n",
    "| `find_element_by_id()` | Retourne le premier élément qui correspond à l'id |\n",
    "| `find_element_by_name()` | Retourne le premier élément qui correspond au name |\n",
    "| `find_element_by_xpath()` | Retourne le premier élément qui correspond au xpath |\n",
    "| `find_element_by_link_text()` | Retourne le premier élément qui correspond au link text |\n",
    "| `find_element_by_partial_link_text()` | Retourne le premier élément qui correspond au partial link text |\n",
    "| `find_element_by_tag_name()` | Retourne le premier élément qui correspond au tag name |\n",
    "| `find_element_by_class_name()` | Retourne le premier élément qui correspond au class name |\n",
    "| `find_element_by_css_selector()` | Retourne le premier élément qui correspond au css selector |\n",
    "| `find_elements_by_id()` | Retourne tous les éléments qui correspondent à l'id |\n",
    "| `find_elements_by_name()` | Retourne tous les éléments qui correspondent au name |\n",
    "| `find_elements_by_xpath()` | Retourne tous les éléments qui correspondent au xpath |\n",
    "| `find_elements_by_link_text()` | Retourne tous les éléments qui correspondent au link text |\n",
    "| `find_elements_by_partial_link_text()` | Retourne tous les éléments qui correspondent au partial link text |\n",
    "| `find_elements_by_tag_name()` | Retourne tous les éléments qui correspondent au tag name |\n",
    "| `find_elements_by_class_name()` | Retourne tous les éléments qui correspondent au class name |\n",
    "| `find_elements_by_css_selector()` | Retourne tous les éléments qui correspondent au css selector |\n",
    "| `click()` | Clique sur l'élément |\n",
    "| `clear()` | Efface le contenu de l'élément |\n",
    "| `send_keys()` | Envoie des données à l'élément |\n",
    "| `submit()` | Soumet le formulaire |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c93e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### REST API\n",
    "\n",
    "Les API REST sont des API en ligne qui permettent de retourner des données à la suite d'une requête HTTP. Les données sont retournées dans un format standardisé (JSON, XML, etc.).\n",
    "\n",
    "L'url d'une API REST est appelé `endpoint`. Il permet de faire une requête HTTP à l'API REST.\n",
    "\n",
    "L'API rest se comporte differement en fonction de la méthode HTTP utilisée.\n",
    "\n",
    "you can find an example of a mock rest api [here](https://jsonplaceholder.typicode.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19034e6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://jsonplaceholder.typicode.com/users\"\n",
    "\n",
    "users = requests.get(url)\n",
    "users = users.json()\n",
    "for user in users:\n",
    "    print(user[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a2483f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "posts = requests.get(\"https://jsonplaceholder.typicode.com/posts\").json()\n",
    "\n",
    "post_count = {}\n",
    "for post in posts:\n",
    "    if post[\"userId\"] in post_count:\n",
    "        post_count[post[\"userId\"]] += 1\n",
    "    else:\n",
    "        post_count[post[\"userId\"]] = 1\n",
    "post_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68073b18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DATASETS\n",
    "\n",
    "Les datasets sont des fichiers qui contiennent des données. Ils sont crées par d'autres personnes et mis à disposition sur internet. Ils sont souvent utilisés pour l'entrainement de modèles de machine learning.\n",
    "\n",
    "Différents moyen de récupérer des datasets:\n",
    "- [Google Colab](https://colab.research.google.com/)\n",
    "- [Kaggle](https://www.kaggle.com/)\n",
    "- [UCI](https://archive.ics.uci.edu/ml/index.php)\n",
    "- [Seaborn](https://seaborn.pydata.org/generated/seaborn.load_dataset.html)\n",
    "- [yfinance](https://pypi.org/project/yfinance/)\n",
    "- [pandas_datareader](https://pandas-datareader.readthedocs.io/en/latest/)\n",
    "- [scikit-learn](https://scikit-learn.org/stable/datasets/index.html)\n",
    "- [tensorflow_datasets](https://www.tensorflow.org/datasets/catalog/overview)\n",
    "- [pytorch_datasets](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "- [pytorch_datasets](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5dec77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Datasets - Seaborn, titanic\n",
    "\n",
    "Le dataset suivant est une base de données qui contient les informations relatives à la survie des passagers du titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719cd2c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "print(titanic.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45733384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the age\n",
    "sns.distplot(titanic['age'])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
