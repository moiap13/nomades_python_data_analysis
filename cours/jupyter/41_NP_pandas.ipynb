{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e01e82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d99275e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is panadas\n",
    "\n",
    "- Pandas is a Python library for data analysis and manipulation.\n",
    "- It is built on top of the NumPy library.\n",
    "- It offers data structures and operations for manipulating numerical tables and time series.\n",
    "- It provides data analysis tools for exploratory data analysis, data cleaning, and data transformation.\n",
    "- It also provides data visualization features.\n",
    "- It's free to use and open source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e4eee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installation\n",
    "\n",
    "To install pandas, you can use the following command:\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6241835",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import pandas\n",
    "\n",
    "To import pandas, you can use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c240e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f69c84",
   "metadata": {},
   "source": [
    "**Note :** When importing pandas, it's by convention to use the alias `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea0b00",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Data Structures\n",
    "\n",
    "Pandas has two main data structures: `Series` and `DataFrames`.\n",
    "\n",
    "- A DataFrame is a two-dimensional labeled data structure with columns of potentially different types.\n",
    "- A Series is a one-dimensional labeled array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e398a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Data Structures\n",
    "### DataFrames\n",
    "\n",
    "A DataFrame is a table. It contains an array of individual entries, each of which has a certain value. Each entry corresponds to a row (or record) and a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6642800",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Yes': [50, 21], 'No': [131, 2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cfdccf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the previous example:\n",
    "  - `Yes` and `No` are the column names\n",
    "  - `50` and `21` are the values in the `Yes` column\n",
    "  - `131` and `2` are the values in the `No` column\n",
    "  - yes/0 is 50; yes/1 is 21; no/0 is 131; no/1 is 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0a39a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DataFrames\n",
    "\n",
    "The `Dataframes` object is not limited to numbers values. It can contain any data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6053f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Bob': ['I liked it.', 'It was awful.'], 'Sue': ['Pretty good.', 'Bland.']})\n",
    "print(df)\n",
    "df[\"Bob\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8495f2",
   "metadata": {},
   "source": [
    "We are using the `pd.DataFrame()` constructor to instaciate these DataFrame objects. \n",
    "\n",
    "The syntax for declaring a new one is a dictionary whose keys are the column names (`Bob` and `Sue` in this example), and whose values are a list of entries. This is the standard way of constructing a new DataFrame, and the one you are most likely to encounter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0fca5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The dictionary-list constructor assigns values to the column labels, but just uses an *ascending count* from 0 (0, 1, 2, 3, ...) for the row labels. Sometimes this is OK, but oftentimes we will want to assign these labels ourselves.\n",
    "\n",
    "The list of row labels used in a DataFrame is known as an `Index`. We can assign values to it by using an index parameter in our constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Bob': ['I liked it.', 'It was awful.'], \n",
    "    'Sue': ['Pretty good.', 'Bland.']\n",
    "}, index=['Product A', 'Product B'])\n",
    "df[\"Bob\"]['Product A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Bob': ['I liked it.', 'It was awful.', 2], \n",
    "              'Sue': ['', 'Bland.', 1]},\n",
    "             index=['Product A', 'Product B', \"Product_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc01c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Data Structures\n",
    "### Series\n",
    "\n",
    "A Series, by contrast, is a sequence of data values. If a DataFrame is a table, a Series is a list :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be5ddf",
   "metadata": {},
   "source": [
    "**Note :** In fact you can create one with nothing more than a python list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb55c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Series\n",
    "\n",
    "You can visualize a Series as a single column of a DataFrame. So you can assign row labels to the Series the same way as before, using an `index` parameter. However, a Series does not have a column name, it only has one overall name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_label = pd.Series([30, 35, 40], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A')\n",
    "print(\"serie_label\", serie_label, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813d75c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Data Structures\n",
    "### Conclusion\n",
    "\n",
    "The Series and the DataFrame are intimately related. It's helpful to think of a `DataFrame` as actually being just a bunch of Series \"glued together\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21659a05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Reading Data Files\n",
    "\n",
    "Being able to create a DataFrame or Series by hand is handy. But, most of the time, we won't actually be creating our own data by hand. Instead, we'll be working with data that already exists.\n",
    "\n",
    "Pandas has built-in methods for reading data from various file formats including CSV, Excel, JSON, and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d9ce7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Reading Data Files\n",
    "\n",
    "Here is a table of the different types of files that pandas can read:\n",
    "\n",
    "| Data Format | Read | Write |\n",
    "|------------|------|-------|\n",
    "| CSV | pd.read_csv | pd.to_csv |\n",
    "| Excel | pd.read_excel | pd.to_excel |\n",
    "| JSON | pd.read_json | pd.to_json |\n",
    "| SQL | pd.read_sql | pd.to_sql |\n",
    "| HTML | pd.read_html | pd.to_html |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1478e806",
   "metadata": {},
   "source": [
    "**Note :** in this notebook we'll use the CSV file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b93f90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv(\"./data/numpy_pandas/dataset/wine-reviews/winemag-data-130k-v2.csv\")\n",
    "wine_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98344241",
   "metadata": {},
   "source": [
    "**Note :** We can see that this dataset has 129971 rows and 14 columns. This is like 1.8 Millions of entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ad6da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Reading Data Files\n",
    "### pd.read_csv()\n",
    "\n",
    "The `pd.read_csv()` method contains many parameters :\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| filepath_or_buffer | The path to the file to read. Can be a URL. |\n",
    "| sep | The separator for the columns. By default, it is a comma. |\n",
    "| delimiter | The separator for the columns. By default, it is a comma. |\n",
    "| header | The row to use as the column names. By default, it is the first row. |\n",
    "| names | The column names. By default, it is None. |\n",
    "| index_col | The column to use as the index. By default, it is None. |\n",
    "| usecols | The columns to use. By default, it is None. |\n",
    "| encoding | The encoding to use. By default, it is None. |\n",
    "| engine | The engine to use. By default, it is None. |\n",
    "| squeeze | If the data is only one column, return a Series. By default, it is False. |\n",
    "| skiprows | The rows to skip. By default, it is None. |\n",
    "| nrows | The number of rows to read. By default, it is None. |\n",
    "| na_values | The values to use for missing values. By default, it is None. |\n",
    "| parse_dates | If True, parse the dates. By default, it is False. |\n",
    "| infer_datetime_format | If True, infer the datetime format. By default, it is False. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588732ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Reading Data Files\n",
    "### Head and Tail\n",
    "\n",
    "We can visulize the first and last rows of a DataFrame:\n",
    "  - If I call directly the `DataFrame` object, I'll see the first 5 rows and the last 5 rows\n",
    "  - If I call the `head()` method, I'll see the first 5 rows\n",
    "  - If I call the `tail()` method, I'll see the last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d212f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "(wine_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627dcacd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "(wine_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6025e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(wine_reviews.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20d9b8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we look at the data more precisely, we can see that the dataset has a built-in index. If we want to use this column as index for the data we need to specify the `index_col` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2def51",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv(\"./data/numpy_pandas/dataset/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)\n",
    "wine_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d916036",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Indexing, Selecting, Assigning\n",
    "### Introduction\n",
    "\n",
    "Selecting specific values of a pandas DataFrame or Series to work on is an implicit step in almost any data operation you'll run, so one of the first things you need to learn in working with data in Python is how to go about selecting the data points relevant to you quickly and effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "reviews = pd.read_csv(\"./data/numpy_pandas/dataset/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3aca87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Indexing, Selecting, Assigning\n",
    "### Native accessors\n",
    "\n",
    "Native Python objects provide good ways of indexing data. Pandas carries all of these over, which helps make it easy to start with.\n",
    "\n",
    "Consider this DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6935ba8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2e8b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In Python, we can access the property of an object by accessing it as an attribute. A `book` object, for example, might have a `title` property, which we can access by calling `book.title`. Columns in a pandas DataFrame work in much the same way.\n",
    "\n",
    "Hence to access the country property of reviews we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf58bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a585f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we have a Python dictionary, we can access its values using the indexing ([]) operator. We can do the same with columns in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64294130",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['country']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97513de",
   "metadata": {},
   "source": [
    "**Note :** These are the two ways of selecting a specific Series out of a DataFrame. Neither of them is more or less syntactically valid than the other, but the indexing operator [] does have the advantage that it can handle column names with reserved characters in them (e.g. if we had a country providence column, reviews.country providence wouldn't work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50629eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.country[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba769d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Indexing, Selecting, Assigning\n",
    "### Indexing in Pandas\n",
    "\n",
    "The indexing operator and attribute selection are nice because they work just like they do in the rest of the Python ecosystem. \n",
    "\n",
    "However, pandas has its own accessor operators, `loc` and `iloc`. For more advanced operations, these are the ones you're supposed to be using\n",
    "\n",
    "- `loc` for label-based indexing\n",
    "- `iloc` for Index-based indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd1c92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Index-based selection\n",
    "\n",
    "`iloc` selects data based on its numerical position in the data. iloc follows this paradigm.\n",
    "\n",
    "To select the first row of data in a DataFrame, we may use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c3571",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Note :** Both `loc` and `iloc` are row-first, column-second. This is the opposite of what we do in native Python, which is column-first, row-second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c2af9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This means that it's marginally easier to retrieve rows, and marginally harder to get retrieve columns. \n",
    "\n",
    "To get a column with iloc, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3189ea2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On its own, the : operator, which also comes from native Python, means \"everything\". When combined with other selectors, however, it can be used to indicate a range of values. For example, to select the country column from just the first, second, and third row, we would do:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefc80e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or, to select just the second and third entries, we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd150b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.iloc[:3, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e7feb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It's also possible to pass a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ac3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.iloc[[0, 10, 20], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ba407",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, it's worth knowing that negative numbers can be used in selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.iloc[-5:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a5e86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Index-based selection\n",
    "\n",
    "The second paradigm for attribute selection is the one followed by the `loc` operator: **label-based selection**. In this paradigm, it's the data index value, not its position, which matters.\n",
    "\n",
    "For example, to get the first entry in `reviews`, we would now do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3640a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.loc[0, 'country']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba4bb2",
   "metadata": {},
   "source": [
    "**Note :** iloc is conceptually simpler than loc because it ignores the dataset's indices. When we use iloc we treat the dataset like a big matrix (a list of lists), one that we have to index into by position. loc, by contrast, uses the information in the indices to do its work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c305720",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since your dataset usually has meaningful indices, it's usually easier to do things using loc instead. For example, here's one operation that's much easier using loc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8096f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.loc[:, ['taster_name', 'taster_twitter_handle', 'points']]\n",
    "reviews.iloc[:, [8, 9, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72905112",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Choosing between `loc` and `iloc`\n",
    "\n",
    "When choosing or transitioning between `loc` and `iloc`, there is one \"gotcha\" worth keeping in mind, which is that the two methods use slightly different indexing schemes.\n",
    "\n",
    "`iloc` uses the Python stdlib indexing scheme, where the first element of the range is included and the last one excluded. So 0:10 will select entries 0,...,9. `loc`, meanwhile, indexes inclusively. So 0:10 will select entries 0,...,10.\n",
    "\n",
    "Why the change? Remember that `loc` can index any stdlib type: strings, for example. If we have a DataFrame with index values Apples, ..., Potatoes, ..., and we want to select \"all the alphabetical fruit choices between Apples and Potatoes\", then it's a heck of a lot more convenient to index `df.loc['Apples':'Potatoes']` than it is to index something like `df.loc['Apples', 'Potatoed']` (`t` coming after `s` in the alphabet).\n",
    "\n",
    "This is particularly confusing when the DataFrame index is a simple numerical list, e.g. 0,...,1000. In this case df.iloc[0:1000] will return 1000 entries, while df.loc[0:1000] return 1001 of them! To get 1000 elements using loc, you will need to go one lower and ask for df.loc[0:999].\n",
    "\n",
    "Otherwise, the semantics of using loc are the same as those for iloc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665bfdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Manipulating the index\n",
    "\n",
    "Label-based selection derives its power from the labels in the index. Critically, the index we use is not immutable. We can manipulate the index in any way we see fit.\n",
    "\n",
    "The `set_index()` method can be used to do the job. Here is what happens when we `set_index` to the `title` field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5687286",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reviews.set_index(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b7c972",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Conditional selection\n",
    "\n",
    "So far we've been indexing various strides of data, using structural properties of the DataFrame itself. To do *interesting* things with the data, however, we often need to ask questions based on conditions.\n",
    "\n",
    "For example, suppose that we're interested specifically in better-than-average wines produced in Italy.\n",
    "\n",
    "We can start by checking if each wine is Italian or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a827a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.country == 'Italy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fbaf63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This operation produced a Series of True/False booleans based on the country of each record. This result can then be used inside of loc to select the relevant data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170059f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "italian_wines = reviews.loc[reviews.country == 'Italy']\n",
    "italian_wines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840237b2",
   "metadata": {},
   "source": [
    "**Note :** This DataFrame has ~20,000 rows. The original had ~130,000. That means that around 15% of wines originate from Italy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d055d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We also wanted to know which ones are better than average. Wines are reviewed on a 80-to-100 point scale, so this could mean wines that accrued at least 90 points.\n",
    "\n",
    "We can use the ampersand (`&`) to bring the two questions together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d33a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.loc[(reviews.country == 'Italy') & (reviews.points >= 90)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbed40f1",
   "metadata": {},
   "source": [
    "Suppose we'll buy any wine that's made in Italy or which is rated above average. For this we use a pipe (|):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61b753",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reviews.loc[(reviews.country == 'Italy') | (reviews.points >= 90)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b6d0f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas Built-in conditinal selectors\n",
    "\n",
    "| Selector | Description |\n",
    "|----------|-------------|\n",
    "| `isin()` | Selects rows where the column contains one or more values |\n",
    "| `isnull()` | Selects rows where the column is null |\n",
    "| `notnull()` | Selects rows where the column is not null |\n",
    "| `between()` | Selects rows where the column is between two values |\n",
    "| `any()` | Selects rows where the column contains at least one non-null value |\n",
    "| `all()` | Selects rows where the column contains all non-null values |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d5a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.loc[reviews.country.isin(['Italy', 'France'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6e9b3b",
   "metadata": {},
   "source": [
    "**Note :** The second is isnull (and its companion notnull). These methods let you highlight values which are (or are not) empty (NaN). For example, to filter out wines lacking a price tag in the dataset, here's what we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa194480",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reviews.loc[reviews.designation.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c25af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Assagning data\n",
    "\n",
    "Going the other way, assigning data to a DataFrame is easy. You can assign either a constant value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b67bf9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reviews['critic'] = 'everyone'\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c1b7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Or with iterable values\n",
    "reviews['index_backwards'] = range(len(reviews)-1, -1, -1)\n",
    "reviews['index_backwards']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37927d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary functions and Maps\n",
    "### Introduction\n",
    "\n",
    "In the last tutorial, we learned how to select relevant data out of a DataFrame or Series. Plucking the right data out of our data representation is critical to getting work done, as we demonstrated in the exercises.\n",
    "\n",
    "However, the data does not always come out of memory in the format we want it in right out of the bat. Sometimes we have to do some more work ourselves to reformat it for the task at hand. This tutorial will cover different operations we can apply to our data to get the input \"just right\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797318d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary functions\n",
    "\n",
    "Pandas provides many simple \"summary functions\" (not an official name) which restructure the data in some useful way. \n",
    "\n",
    "For example, consider the `describe()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c27ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "reviews = pd.read_csv(\"./data/numpy_pandas/dataset/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)\n",
    "reviews.points.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e4ceb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This method generates a high-level summary of the attributes of the given column. It is type-aware, meaning that its output changes based on the data type of the input. The output above only makes sense for numerical data; for string data here's what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9229f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.taster_name.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159639a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want to get some particular simple summary statistic about a column in a DataFrame or a Series, there is usually a helpful pandas function that makes it happen.\n",
    "\n",
    "For example, to see the mean of the points allotted (e.g. how well an averagely rated wine does), we can use the mean() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.points.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d63fb77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To see a list of unique values we can use the unique() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.taster_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8651f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To see a list of unique values and how often they occur in the dataset, we can use the value_counts() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.taster_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee238aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maps\n",
    "\n",
    "A map is a term, borrowed from mathematics, for a function that takes one set of values and \"maps\" them to another set of values. In data science we often have a need for creating new representations from existing data, or for transforming data from the format it is in now to the format that we want it to be in later. Maps are what handle this work, making them extremely important for getting your work done!\n",
    "\n",
    "There are two mapping methods that you will use often.\n",
    "  - `map()`\n",
    "  - `apply()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095189a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`map()`  is the first, and slightly simpler one. For example, suppose that we wanted to remean the scores the wines received to 0. We can do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23905a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_points_mean = reviews.points.mean()\n",
    "reviews.points.map(lambda p: p - review_points_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c5751",
   "metadata": {},
   "source": [
    "**Note :** The function you pass to map() should expect a single value from the Series (a point value, in the above example), and return a transformed version of that value. \n",
    "\n",
    "map() returns a new Series where all the values have been transformed by your function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33a83b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "apply() is the equivalent method if we want to transform a whole DataFrame by calling a custom method on each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remean_points(row):\n",
    "    row.points = row.points - review_points_mean\n",
    "    return row\n",
    "\n",
    "reviews.apply(remean_points, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633cbe9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we had called reviews.apply() with axis='index', then instead of passing a function to transform each row, we would need to give a function to transform each column.\n",
    "\n",
    "**Note :** that map() and apply() return new, transformed Series and DataFrames, respectively. They don't modify the original data they're called on. If we look at the first row of reviews, we can see that it still has its original points value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121dd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59752e82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas provides many common mapping operations as built-ins. For example, here's a faster way of remeaning our points column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_points_mean = reviews.points.mean()\n",
    "reviews.points - review_points_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e11602",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this code we are performing an operation between a lot of values on the left-hand side (everything in the Series) and a single value on the right-hand side (the mean value). Pandas looks at this expression and figures out that we must mean to subtract that mean value from every value in the dataset.\n",
    "\n",
    "Pandas will also understand what to do if we perform these operations between Series of equal length. For example, an easy way of combining country and region information in the dataset would be to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.country + \" - \" + reviews.region_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb9d9fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These operators are faster than map() or apply() because they use speed ups built into pandas. All of the standard Python operators (>, <, ==, and so on) work in this manner.\n",
    "\n",
    "However, they are not as flexible as map() or apply(), which can do more advanced things, like applying conditional logic, which cannot be done with addition and subtraction alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e8b7b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Grouping and sorting\n",
    "### Introduction\n",
    "\n",
    "Maps allow us to transform data in a DataFrame or Series one value at a time for an entire column. However, often we want to group our data, and then do something specific to the group the data is in.\n",
    "\n",
    "As you'll learn, we do this with the groupby() operation. We'll also cover some additional topics, such as more complex ways to index your DataFrames, along with how to sort your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c464a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Groupwise analysis\n",
    "\n",
    "One function we've been using heavily thus far is the value_counts() function. We can replicate what value_counts() does by doing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e12230",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.groupby('points').points.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f66e84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "groupby() created a group of reviews which allotted the same point values to the given wines. Then, for each of these groups, we grabbed the points() column and counted how many times it appeared.  value_counts() is just a shortcut to this groupby() operation.\n",
    "  \n",
    "We can use any of the summary functions we've used before with this data. For example, to get the cheapest wine in each point value category, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d090c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews.groupby('points').price.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6738ea0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can think of each group we generate as being a slice of our DataFrame containing only data with values that match. This DataFrame is accessible to us directly using the apply() method, and we can then manipulate the data in any way we see fit. \n",
    "\n",
    "For example, here's one way of selecting the name of the first wine reviewed from each winery in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.groupby('winery').apply(lambda df: df.title.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f617a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For even more fine-grained control, you can also group by more than one column.\n",
    "\n",
    "For an example, here's how we would pick out the best wine by country and province:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae65a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.groupby(['country', 'province']).apply(lambda df: df.loc[df.points.idxmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ee718",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another groupby() method worth mentioning is agg(), which lets you run a bunch of different functions on your DataFrame simultaneously. \n",
    "\n",
    "For example, we can generate a simple statistical summary of the dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.groupby(['country']).price.agg([len, min, max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5889898",
   "metadata": {},
   "source": [
    "**Note :** Effective use of groupby() will allow you to do lots of really powerful things with your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ff484",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multi-indexes\n",
    "\n",
    "In all of the examples we've seen thus far we've been working with DataFrame or Series objects with a single-label index. groupby() is slightly different in the fact that, depending on the operation we run, it will sometimes result in what is called a multi-index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7248f85b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A multi-index differs from a regular index in that it has multiple levels. \n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a324e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_reviewed = reviews.groupby(['country', 'province']).description.agg([len])\n",
    "countries_reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = countries_reviewed.index\n",
    "type(mi)\n",
    "mi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521f1c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Multi-indices have several methods for dealing with their tiered structure which are absent for single-level indices. They also require two levels of labels to retrieve a value. Dealing with multi-index output is a common \"gotcha\" for users new to pandas.\n",
    "\n",
    "The use cases for a multi-index are detailed alongside instructions on using them in the MultiIndex / Advanced Selection section of the pandas documentation.\n",
    "\n",
    "However, in general the multi-index method you will use most often is the one for converting back to a regular index, the reset_index() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_reviewed.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c80680",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sorting\n",
    "\n",
    "Looking again at countries_reviewed we can see that grouping returns data in index order, not in value order. That is to say, when outputting the result of a groupby, the order of the rows is dependent on the values in the index, not in the data.\n",
    "\n",
    "To get data in the order want it in we can sort it ourselves. The sort_values() method is handy for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_reviewed = countries_reviewed.reset_index()\n",
    "countries_reviewed.sort_values(by='len')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbd8802",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "sort_values() defaults to an ascending sort, where the lowest values go first. However, most of the time we want a descending sort, where the higher numbers go first. That goes thusly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a42764",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_reviewed.sort_values(by='len', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d2e71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To sort by index values, use the companion method sort_index(). This method has the same arguments and default order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a20aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_reviewed.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d9536",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, know that you can sort by more than one column at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deebfe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countries_reviewed.sort_values(by=['country', 'len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f103180",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "countries_reviewed.sort_values(by=['country', 'len'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f46070",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.sort_values(by=[\"price\"], ascending=False).iloc[0,:].name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cceac8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - Data types and missing values\n",
    "### Introduction\n",
    "\n",
    "Pandas can works with differents data types and it will create new data types. We'll also see how we can replace and deal with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02f3f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dtypes\n",
    "\n",
    "The data type for a column in a DataFrame or a Series is known as the dtype.\n",
    "\n",
    "You can use the dtype property to grab the type of a specific column. For instance, we can get the dtype of the price column in the reviews DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c47323",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.price.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5790ac9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternatively, the dtypes property returns the dtype of every column in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ddb3d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Data types tell us something about how pandas is storing the data internally. float64 means that it's using a 64-bit floating point number; int64 means a similarly sized integer instead, and so on.\n",
    "\n",
    "One peculiarity to keep in mind (and on display very clearly here) is that columns consisting entirely of strings do not get their own type; they are instead given the object type.\n",
    "\n",
    "It's possible to convert a column of one type into another wherever such a conversion makes sense by using the astype() function. \n",
    "\n",
    "For example, we may transform the points column from its existing int64 data type into a float64 data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de87848",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews.points.dtypes)\n",
    "reviews.points.astype('float64').astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb7879",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A DataFrame or Series index has its own dtype, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f29b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.index.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40accbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Missing data\n",
    "\n",
    "Entries missing values are given the value NaN, short for \"Not a Number\". For technical reasons these NaN values are always of the float64 dtype.\n",
    "\n",
    "Pandas provides some methods specific to missing data. To select NaN entries you can use pd.isnull() (or its companion pd.notnull()). This is meant to be used thusly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2704b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[pd.isnull(reviews.country)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa610f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Replacing missing values is a common operation. Pandas provides a really handy method for this problem: fillna(). fillna() provides a few different strategies for mitigating such data. For example, we can simply replace each NaN with an \"Unknown\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.region_2.fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0d0961",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or we could fill each missing value with the first non-null value that appears sometime after the given record in the database. This is known as the backfill strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20e9d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternatively, we may have a non-null value that we would like to replace. For example, suppose that since this dataset was published, reviewer Kerin O'Keefe has changed her Twitter handle from @kerinokeefe to @kerino. One way to reflect this in the dataset is using the replace() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.taster_twitter_handle.replace(\"@kerinokeefe\", \"@kerino\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0131ab59",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The replace() method is worth mentioning here because it's handy for replacing missing data which is given some kind of sentinel value in the dataset: things like \"Unknown\", \"Undisclosed\", \"Invalid\", and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b8e0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also choose to not use a row that has missing data by using the dropna() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169852c2",
   "metadata": {},
   "source": [
    "the dropna() method will remove any row that has missing data.\n",
    "the inplace parameter will modify the original DataFrame rather than returning a new one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b675be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas - renamming and combining\n",
    "### Introduction\n",
    "\n",
    "Oftentimes data will come to us with column names, index names, or other naming conventions that we are not satisfied with. In that case, you'll learn how to use pandas functions to change the names of the offending entries to something better.\n",
    "\n",
    "You'll also explore how to combine data from multiple DataFrames and/or Series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af560a10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Renaming\n",
    "\n",
    "The first function we'll introduce here is rename(), which lets you change index names and/or column names. \n",
    "\n",
    "For example, to change the points column in our dataset to score, we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9bf14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.rename(columns={'points': 'score'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c52427",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "rename() lets you rename index or column values by specifying a index or column keyword parameter, respectively. It supports a variety of input formats, but usually a Python dictionary is the most convenient. Here is an example using it to rename some elements of the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be87ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.rename(index={4: 'firstEntry', 10: 'secondEntry'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ed2a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You'll probably rename columns very often, but rename index values very rarely. For that, set_index() is usually more convenient.\n",
    "\n",
    "Both the row index and the column index can have their own name attribute. The complimentary rename_axis() method may be used to change these names. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.rename_axis(\"wines\", axis='rows').rename_axis(\"fields\", axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8c17c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combining\n",
    "\n",
    "When performing operations on a dataset, we will sometimes need to combine different DataFrames and/or Series in non-trivial ways. Pandas has three core methods for doing this. In order of increasing complexity, these are concat(), join(), and merge(). Most of what merge() can do can also be done more simply with join(), so we will omit it and focus on the first two functions here.\n",
    "\n",
    "The simplest combining method is concat(). Given a list of elements, this function will smush those elements together along an axis.\n",
    "\n",
    "This is useful when we have data in different DataFrame or Series objects but having the same fields (columns). One example: the YouTube Videos dataset, which splits the data up based on country of origin (e.g. Canada and the UK, in this example). If we want to study multiple countries simultaneously, we can use concat() to smush them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7674911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "canadian_youtube = pd.read_csv(\"./data/numpy_pandas/dataset/youtube/CAvideos.csv\")\n",
    "print(canadian_youtube.shape)\n",
    "british_youtube = pd.read_csv(\"./data/numpy_pandas/dataset/youtube/GBvideos.csv\")\n",
    "print(british_youtube.shape)\n",
    "\n",
    "pd.concat([canadian_youtube, british_youtube])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5005f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The middlemost combiner in terms of complexity is join(). join() lets you combine different DataFrame objects which have an index in common. For example, to pull down videos that happened to be trending on the same day in both Canada and the UK, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca4034",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "left = canadian_youtube.set_index(['title', 'trending_date'])\n",
    "right = british_youtube.set_index(['title', 'trending_date'])\n",
    "\n",
    "left.join(right, lsuffix='_CAN', rsuffix='_UK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd502693",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here we do a join on two DataFrames based on the index of the two DataFrames. The lsuffix and rsuffix parameters are used to indicate the suffixes of the column names in the left and right DataFrame, respectively.\n",
    "\n",
    "The lsuffix and rsuffix parameters are necessary here because the data has the same column names in both British and Canadian datasets. If this wasn't true (because, say, we'd renamed them beforehand) we wouldn't need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range(\"1/1/2000\", periods=1000))\n",
    "ts = ts.cumsum()\n",
    "ts.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45e0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
